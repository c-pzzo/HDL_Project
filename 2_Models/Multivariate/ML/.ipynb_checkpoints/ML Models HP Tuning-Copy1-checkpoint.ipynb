{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1972762e",
   "metadata": {},
   "source": [
    "# About\n",
    "Hyperparameter optimization is required to get the most out of your machine learning models.\n",
    "\n",
    "Hyperparameters are points of choice or configuration that allow a machine learning model to be customized for a specific task or dataset.\n",
    "\n",
    "Parameters are different from hyperparameters. Parameters are learned automatically; hyperparameters are set manually to help guide the learning process.\n",
    "\n",
    "Choosing a hyperparameter grid is probably the most difficult part of hyperparameter tuning: it's nearly impossible ahead of time to say which values of hyperparameters will work well and the optimal settings will depend on the dataset. Moreover, the hyperparameters have complex interactions with each other which means that just tuning one at a time doesn't work because when we start changing other hyperparameters that will affect the one we just tuned!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b72428",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d4cf86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"/home/cesar/Python_NBs/HDL_Project/HDL_Project/global_fv.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f177fd95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/cesar/Python_NBs/HDL_Project/HDL_Project/2_Models/Multivariate/ML'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Save trained models\n",
    "import joblib\n",
    "\n",
    "# Data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.multiclass import type_of_target\n",
    "\n",
    "# Hypertuning tools\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import SCORERS\n",
    "\n",
    "# Nonlinear models\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import svm\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "\n",
    "# Ensemble models\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Clone of time class\n",
    "s = t\n",
    "\n",
    "# Random seed\n",
    "import random\n",
    "random.seed(101)\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69844e52",
   "metadata": {},
   "source": [
    "# User-Defined Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27563f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyper_tuning(model, space, X, y):\n",
    "    # The searching algorithm includes a “cv” argument that allows:\n",
    "    # a) An integer number of folds to be specified, e.g. 5\n",
    "    #cross_val = 5\n",
    "    # b) A configured cross-validation object.\n",
    "    kfold = KFold(n_splits=3, shuffle=False)\n",
    "\n",
    "    # The scoring metric must be maximizing, meaning better models result in larger scores.\n",
    "    scoring_metric = 'neg_mean_squared_error'\n",
    "\n",
    "    # Search for best hyperparameters\n",
    "    grid = RandomizedSearchCV(estimator=model, \n",
    "                              param_distributions=search_space, \n",
    "                              cv=kfold, \n",
    "                              n_iter=50,\n",
    "                              scoring=scoring_metric)\n",
    "\n",
    "    result = grid.fit(X_test, y_test)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7660cd23",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c08cdff",
   "metadata": {},
   "source": [
    "## Sample preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d22dc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_table = \"sima_station_CE\"\n",
    "target = \"pm25\"\n",
    "\n",
    "# Define columns of interest from sql table\n",
    "#     Select all columns:\n",
    "column = \"*\"\n",
    "#     Select specific columns:\n",
    "#column = \"datetime, prs, rainf, rh, sr, tout, wdr, wsr, \" + str(target)\n",
    "\n",
    "# Filter data with WHERE command\n",
    "sql_where = \"where datetime > \\'2020-03-01\\'\"\n",
    "\n",
    "# Initialize class to create multivariate samples:\n",
    "multi_ts = multivariate_samples(sql_table, column, sql_where)\n",
    "\n",
    "# Datasets can't be trained with sample batches by default. So parameter is 1.\n",
    "X, y = multi_ts.samples_creation(1, target)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X[:,0,:], y, test_size = 0.30, shuffle= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b56c7073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'continuous'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type_of_target(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f7bd2f",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b04d179",
   "metadata": {},
   "source": [
    "## Objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1adcfceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['accuracy',\n",
       " 'adjusted_mutual_info_score',\n",
       " 'adjusted_rand_score',\n",
       " 'average_precision',\n",
       " 'balanced_accuracy',\n",
       " 'completeness_score',\n",
       " 'explained_variance',\n",
       " 'f1',\n",
       " 'f1_macro',\n",
       " 'f1_micro',\n",
       " 'f1_samples',\n",
       " 'f1_weighted',\n",
       " 'fowlkes_mallows_score',\n",
       " 'homogeneity_score',\n",
       " 'jaccard',\n",
       " 'jaccard_macro',\n",
       " 'jaccard_micro',\n",
       " 'jaccard_samples',\n",
       " 'jaccard_weighted',\n",
       " 'max_error',\n",
       " 'mutual_info_score',\n",
       " 'neg_brier_score',\n",
       " 'neg_log_loss',\n",
       " 'neg_mean_absolute_error',\n",
       " 'neg_mean_absolute_percentage_error',\n",
       " 'neg_mean_gamma_deviance',\n",
       " 'neg_mean_poisson_deviance',\n",
       " 'neg_mean_squared_error',\n",
       " 'neg_mean_squared_log_error',\n",
       " 'neg_median_absolute_error',\n",
       " 'neg_root_mean_squared_error',\n",
       " 'normalized_mutual_info_score',\n",
       " 'precision',\n",
       " 'precision_macro',\n",
       " 'precision_micro',\n",
       " 'precision_samples',\n",
       " 'precision_weighted',\n",
       " 'r2',\n",
       " 'rand_score',\n",
       " 'recall',\n",
       " 'recall_macro',\n",
       " 'recall_micro',\n",
       " 'recall_samples',\n",
       " 'recall_weighted',\n",
       " 'roc_auc',\n",
       " 'roc_auc_ovo',\n",
       " 'roc_auc_ovo_weighted',\n",
       " 'roc_auc_ovr',\n",
       " 'roc_auc_ovr_weighted',\n",
       " 'top_k_accuracy',\n",
       " 'v_measure_score']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(SCORERS.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa61ce7",
   "metadata": {},
   "source": [
    "# Random Search\n",
    "RandomizedSearchCV for random search evaluates models for a given hyperparameter vector using cross-validation, hence the “CV” suffix of each class name.\n",
    "\n",
    "It requires two arguments. \n",
    "1. The first is the model that you are optimizing. This is an instance of the model with values of hyperparameters set that you want to optimize. \n",
    "2. The second is the search space. This is defined as a dictionary where the names are the hyperparameter arguments to the model and the values are discrete values or a distribution of values to sample in the case of a random search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f606afc",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors\n",
    "KNeighborsRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb794f54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithm': 'auto',\n",
       " 'leaf_size': 30,\n",
       " 'metric': 'minkowski',\n",
       " 'metric_params': None,\n",
       " 'n_jobs': None,\n",
       " 'n_neighbors': 5,\n",
       " 'p': 2,\n",
       " 'weights': 'uniform'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select an algorithm\n",
    "model = KNeighborsRegressor()\n",
    "model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0750b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define search space\n",
    "ss_dictionary = {\n",
    "    'n_neighbors': list(range(1,10)),\n",
    "    'weights': list(['uniform', 'distance']),\n",
    "    'algorithm': list(['auto', 'ball_tree', 'kd_tree', 'brute']),\n",
    "    'leaf_size': list(range(15, 45)),\n",
    "    'p': list([1,2]),\n",
    "    'metric': list(['euclidean', 'manhattan','chebyshev', 'minkowski']),\n",
    "    # The search can be made parallel using various if not all of your CPU cores \n",
    "    # We can set it to -1 to automatically use all of the cores in the system.\n",
    "    'n_jobs': list([-1])\n",
    "}\n",
    "    \n",
    "search_space = [ss_dictionary] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bafdedb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time is 8.132417 seconds.\n",
      "-133.50513381495009\n",
      "\n",
      "KNeighborsRegressor(leaf_size=17, metric='manhattan', n_jobs=-1, n_neighbors=9,\n",
      "                    p=1, weights='distance')\n",
      "\n",
      "{'weights': 'distance', 'p': 1, 'n_neighbors': 9, 'n_jobs': -1, 'metric': 'manhattan', 'leaf_size': 17, 'algorithm': 'auto'}\n"
     ]
    }
   ],
   "source": [
    "t.tic()\n",
    "result_KNN = hyper_tuning(model, search_space, X_train, y_train)\n",
    "t.toc(restart=True)\n",
    "# Get the results\n",
    "print(result_KNN.best_score_)\n",
    "print(\"\")\n",
    "print(result_KNN.best_estimator_)\n",
    "print(\"\")\n",
    "print(result_KNN.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297245af",
   "metadata": {},
   "source": [
    "## Classification and Regression Tree\n",
    "DecisionTreeRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b303d98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ccp_alpha': 0.0,\n",
       " 'criterion': 'squared_error',\n",
       " 'max_depth': None,\n",
       " 'max_features': None,\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'random_state': None,\n",
       " 'splitter': 'best'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select an algorithm\n",
    "model = DecisionTreeRegressor()\n",
    "model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94ce5735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define search space\n",
    "ss_dictionary = {\n",
    "    'criterion': list(['squared_error', 'friedman_mse', 'absolute_error', 'poisson'])\n",
    "    , 'splitter': list(['best', 'random'])\n",
    "    , 'max_depth': list(range(1,10))\n",
    "    , 'min_samples_split': list(range(2,10))\n",
    "    , 'min_samples_leaf': list(range(1,10))\n",
    "    , 'min_weight_fraction_leaf': list(np.linspace(0.0,0.5))\n",
    "}\n",
    "\n",
    "search_space = [ss_dictionary] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32313cfa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time is 5.114506 seconds.\n",
      "-154.3718749133663\n",
      "\n",
      "DecisionTreeRegressor(max_depth=3, min_samples_leaf=8, min_samples_split=8,\n",
      "                      min_weight_fraction_leaf=0.01020408163265306)\n",
      "\n",
      "{'splitter': 'best', 'min_weight_fraction_leaf': 0.01020408163265306, 'min_samples_split': 8, 'min_samples_leaf': 8, 'max_depth': 3, 'criterion': 'squared_error'}\n"
     ]
    }
   ],
   "source": [
    "t.tic()\n",
    "result_DTR = hyper_tuning(model, search_space, X_train, y_train)\n",
    "t.toc(restart=True)\n",
    "\n",
    "# Get the results\n",
    "print(result_DTR.best_score_)\n",
    "print(\"\")\n",
    "print(result_DTR.best_estimator_)\n",
    "print(\"\")\n",
    "print(result_DTR.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8b3674",
   "metadata": {},
   "source": [
    "## Support Vector Regression - Polynomial\n",
    "svm.SVR(kernel='poly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4cc46eac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'cache_size': 200,\n",
       " 'coef0': 0.0,\n",
       " 'degree': 3,\n",
       " 'epsilon': 0.1,\n",
       " 'gamma': 'scale',\n",
       " 'kernel': 'rbf',\n",
       " 'max_iter': -1,\n",
       " 'shrinking': True,\n",
       " 'tol': 0.001,\n",
       " 'verbose': False}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select an algorithm\n",
    "model = svm.SVR()\n",
    "model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abcdc107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define search space\n",
    "ss_dictionary = {\n",
    "    'kernel': list(['poly'])\n",
    "    # `degree` is a parameter used when kernel is set to ‘poly’.\n",
    "    , 'degree': list([0, 2, 3, 4, 5, 6])\n",
    "    # Gamma is a parameter for non linear hyperplanes. \n",
    "    # The higher the gamma value it tries to exactly fit the training data set\n",
    "    , 'gamma' : list([0.1, 1, 10, 100])\n",
    "    # C is the penalty parameter of the error term. \n",
    "    # It controls the trade off between smooth decision boundary and classifying the training points correctly.\n",
    "    , 'C': list([0.1, 1, 10, 100, 1000])\n",
    "}\n",
    "\n",
    "search_space = [ss_dictionary] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df7656f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#if(True):\n",
    "t.tic()\n",
    "result_SVM_poly = hyper_tuning(model, search_space, X_train, y_train)\n",
    "t.toc(restart=True)\n",
    "\n",
    "# Get the results\n",
    "print(result_SVM_poly.best_score_)\n",
    "print(\"\")\n",
    "print(result_SVM_poly.best_estimator_)\n",
    "print(\"\")\n",
    "print(result_SVM_poly.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd31d89a",
   "metadata": {},
   "source": [
    "## Support Vector Regression - RBF\n",
    "svm.SVR(kernel='rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94870cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select an algorithm\n",
    "model = svm.SVR()\n",
    "model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4a6d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define search space\n",
    "ss_dictionary = {\n",
    "    'kernel': list(['rbf'])\n",
    "    # `degree` is a parameter used when kernel is set to ‘poly’.\n",
    "    , 'degree': list([0, 2, 3, 4, 5, 6])\n",
    "    # Gamma is a parameter for non linear hyperplanes. \n",
    "    # The higher the gamma value it tries to exactly fit the training data set\n",
    "    , 'gamma' : list([0.1, 1, 10, 100])\n",
    "    # C is the penalty parameter of the error term. \n",
    "    # It controls the trade off between smooth decision boundary and classifying the training points correctly.\n",
    "    , 'C': list([0.1, 1, 10, 100, 1000])\n",
    "}\n",
    "\n",
    "search_space = [ss_dictionary] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88de60fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.tic()\n",
    "result_SVM_RBF = hyper_tuning(model, search_space, X_train, y_train)\n",
    "t.toc(restart=True)\n",
    "\n",
    "# Get the results\n",
    "print(result_SVM_RBF.best_score_)\n",
    "print(\"\")\n",
    "print(result_SVM_RBF.best_estimator_)\n",
    "print(\"\")\n",
    "print(result_SVM_RBF.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c99691c",
   "metadata": {},
   "source": [
    "## Support Vector Regression - Linear\n",
    "svm.SVR(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3c8aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select an algorithm\n",
    "model = svm.SVR()\n",
    "model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c68ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define search space\n",
    "ss_dictionary = {\n",
    "    'kernel': list(['linear'])\n",
    "    # `degree` is a parameter used when kernel is set to ‘poly’.\n",
    "    , 'degree': list([0, 2, 3, 4, 5, 6])\n",
    "    # Gamma is a parameter for non linear hyperplanes. \n",
    "    # The higher the gamma value it tries to exactly fit the training data set\n",
    "    , 'gamma' : list([0.1, 1, 10, 100])\n",
    "    # C is the penalty parameter of the error term. \n",
    "    # It controls the trade off between smooth decision boundary and classifying the training points correctly.\n",
    "    , 'C': list([0.1, 1, 10, 100, 1000])\n",
    "}\n",
    "\n",
    "search_space = [ss_dictionary] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9d57d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.tic()\n",
    "result_SVM_Linear = hyper_tuning(model, search_space, X_train, y_train)\n",
    "t.toc(restart=True)\n",
    "\n",
    "# Get the results\n",
    "print(result_SVM_Linear.best_score_)\n",
    "print(\"\")\n",
    "print(result_SVM_Linear.best_estimator_)\n",
    "print(\"\")\n",
    "print(result_SVM_Linear.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760d5cee",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes\n",
    "GaussianProcessRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d743d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select an algorithm\n",
    "model = GaussianProcessRegressor()\n",
    "model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8ced3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define search space\n",
    "ss_dictionary = {\n",
    "    \n",
    "}\n",
    "\n",
    "search_space = [ss_dictionary] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54f03d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_GNB = hyper_tuning(model, list(space), X_train, y_train)\n",
    "\n",
    "# Get the results\n",
    "print(result_GNB.best_score_)\n",
    "print(\"\")\n",
    "print(result_GNB.best_estimator_)\n",
    "print(\"\")\n",
    "print(result_GNB.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20502b33",
   "metadata": {},
   "source": [
    "## Bagging Regressor'\n",
    "BaggingRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59706fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select an algorithm\n",
    "model = BaggingRegressor()\n",
    "model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed19e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define search space\n",
    "ss_dictionary = {\n",
    "    \n",
    "}\n",
    "\n",
    "search_space = [ss_dictionary] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8065f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_Bagging = hyper_tuning(model, list(space), X_train, y_train)\n",
    "\n",
    "# Get the results\n",
    "print(result_Bagging.best_score_)\n",
    "print(\"\")\n",
    "print(result_Bagging.best_estimator_)\n",
    "print(\"\")\n",
    "print(result_Bagging.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639436d6",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1add929b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select an algorithm\n",
    "model = RandomForestRegressor()\n",
    "model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abf1537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define search space\n",
    "ss_dictionary = {\n",
    "    \n",
    "}\n",
    "\n",
    "search_space = [ss_dictionary] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d9a3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_RF = hyper_tuning(model, list(space), X_train, y_train)\n",
    "\n",
    "# Get the results\n",
    "print(result_RF.best_score_)\n",
    "print(\"\")\n",
    "print(result_RF.best_estimator_)\n",
    "print(\"\")\n",
    "print(result_RF.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0447f052",
   "metadata": {},
   "source": [
    "## Extra-trees regressor\n",
    "ExtraTreesRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5ae84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select an algorithm\n",
    "model = ExtraTreesRegressor()\n",
    "model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ebe9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define search space\n",
    "ss_dictionary = {\n",
    "    \n",
    "}\n",
    "\n",
    "search_space = [ss_dictionary] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a98b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_ETR = hyper_tuning(model, list(space), X_train, y_train)\n",
    "\n",
    "# Get the results\n",
    "print(result_ETR.best_score_)\n",
    "print(result_ETR.best_estimator_)\n",
    "print(result_ETR.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b2096e",
   "metadata": {},
   "source": [
    "## XG Boost \n",
    "XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410f4f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select an algorithm\n",
    "model = XGBRegressor()\n",
    "model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21d4186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define search space\n",
    "ss_dictionary = {\n",
    "    \n",
    "}\n",
    "\n",
    "search_space = [ss_dictionary] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86644010",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_XGB = hyper_tuning(model, list(space), X_train, y_train)\n",
    "\n",
    "# Get the results\n",
    "print(result_XGB.best_score_)\n",
    "print(\"\")\n",
    "print(result_XGB.best_estimator_)\n",
    "print(\"\")\n",
    "print(result_XGB.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3842f166",
   "metadata": {},
   "source": [
    "# Sources:\n",
    "* sklearn.model_selection.RandomizedSearchCV <br>\n",
    "    - https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html \n",
    "    - https://scikit-learn.org/stable/modules/grid_search.html?highlight=randomsearchcv\n",
    "* sklearn.model_selection.KFold <br>\n",
    "    - https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html\n",
    "    - https://machinelearningmastery.com/k-fold-cross-validation/\n",
    "\n",
    "\n",
    "## Models\n",
    "* DecisionTreeRegressor()\n",
    "    - https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html\n",
    "* pmdarima\n",
    "    - https://towardsdatascience.com/efficient-time-series-using-pythons-pmdarima-library-f6825407b7f0\n",
    "* SVM\n",
    "    - https://medium.com/all-things-ai/in-depth-parameter-tuning-for-svc-758215394769\n",
    "\n",
    "## Metrics\n",
    "* Metrics and scoring: quantifying the quality of predictions\n",
    "    - https://scikit-learn.org/stable/modules/model_evaluation.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
