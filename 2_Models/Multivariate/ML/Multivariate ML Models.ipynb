{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de07487c",
   "metadata": {},
   "source": [
    "# About\n",
    "Multivariate ML model training. Single step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b389dcaf",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3603bb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"/home/cesar/Python_NBs/HDL_Project/HDL_Project/global_fv.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfd85f73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/cesar/Python_NBs/HDL_Project/HDL_Project/2_Models/Multivariate/ML'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Save trained models\n",
    "import joblib\n",
    "\n",
    "# Data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Nonlinear models\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import svm\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "\n",
    "# Ensemble models\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Clone of time class\n",
    "s = t\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c93e0a",
   "metadata": {},
   "source": [
    "# Global parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6203cc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 101"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0724979a",
   "metadata": {},
   "source": [
    "# User-Defined Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc9f812c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dict of standard models to evaluate {name:object}\n",
    "def define_models():\n",
    "    models=dict()\n",
    "    \n",
    "    # nonlinear models\n",
    "    models['k-Nearest Neighbors'] = KNeighborsRegressor(weights= 'distance'\n",
    "                                                         , p= 2\n",
    "                                                         , n_neighbors= 8\n",
    "                                                         , n_jobs= -1\n",
    "                                                         , metric= 'manhattan'\n",
    "                                                         , leaf_size= 30\n",
    "                                                         , algorithm= 'brute')\n",
    "    \n",
    "    models['Decision Tree Regressor'] = DecisionTreeRegressor(splitter= 'best'\n",
    "                                                        , min_weight_fraction_leaf= 0.0\n",
    "                                                        , min_samples_split= 6\n",
    "                                                        , min_samples_leaf= 4\n",
    "                                                        , max_depth= 7\n",
    "                                                        , criterion= 'friedman_mse')\n",
    "    \n",
    "    models['Support Vector Regression - Polynomial'] = svm.SVR(kernel='poly')\n",
    "    \n",
    "    models['Support Vector Regression - RBF'] = svm.SVR(kernel= 'rbf'\n",
    "                                                         , gamma= 0.1\n",
    "                                                         , C= 1000)\n",
    "    \n",
    "    models['Support Vector Regression - Linear'] = svm.SVR(kernel='linear'\n",
    "                                                           , gamma= 1\n",
    "                                                           , C= 10)\n",
    "    \n",
    "    # ensemble models\n",
    "    models['Random Forest'] = RandomForestRegressor(n_estimators= 500\n",
    "                                                    , min_samples_split= 3\n",
    "                                                    , max_features= 8\n",
    "                                                    , max_depth= 18.0)\n",
    "    \n",
    "    models['Extra-trees classifier'] = ExtraTreesRegressor(n_estimators= 100\n",
    "                                                           , min_samples_split= 5\n",
    "                                                           , max_features= 11\n",
    "                                                           , max_depth= 18.0\n",
    "                                                           , criterion= 'squared_error')\n",
    "    \n",
    "    models['XG Boost'] = XGBRegressor(subsample= 0.5\n",
    "                                      , n_estimators= 1000\n",
    "                                      , max_depth= 20\n",
    "                                      , learning_rate= 0.01\n",
    "                                      , colsample_bytree= 0.9\n",
    "                                      , colsample_bylevel= 0.5)\n",
    "\n",
    "    print( 'Defined %d models:' % len(models))\n",
    "    print()\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dffbbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate a single model\n",
    "def single_model_evaluation(X_train, y_train, X_test, y_test, name, model):\n",
    "    # fit the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Save the trained model\n",
    "    filename = 'trained_ml_models/{}.sav'.format(name)\n",
    "    joblib.dump(model, filename)\n",
    "    \n",
    "    # make predictions\n",
    "    y_prediction = model.predict(X_test)\n",
    "    \n",
    "    metrics = dict()\n",
    "    # evaluate predictions\n",
    "    # accuracy = accuracy_score(y_test, y_prediction) * 100\n",
    "    metrics[\"RMSE\"] = mean_squared_error(y_test, y_prediction, squared=False)\n",
    "    metrics[\"MAE\"] = mean_absolute_error(y_test, y_prediction)\n",
    "    metrics[\"MAPE\"] = mean_absolute_percentage_error(y_test, y_prediction)\n",
    "    metrics[\"R^2\"] = r2_score(y_test, y_prediction)\n",
    "    metrics[\"Max Error\"] = max_error(y_test, y_prediction)    \n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0681d3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate a dict of models {name:object}, returns {name:score}\n",
    "def multiple_model_evaluation(X_train, y_train, X_test, y_test, models):\n",
    "    metrics_df = pd.DataFrame()\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        # evaluate the model\n",
    "        s.tic()\n",
    "        tmp_df = pd.DataFrame(single_model_evaluation(X_train, y_train, X_test, y_test, name, model), index=[0])\n",
    "        tmp_df.insert(0, \"Model Name\", name, True)\n",
    "        tmp_df.insert(0, \"Type\", \"ML\", True)\n",
    "        metrics_df = metrics_df.append(tmp_df)\n",
    "        print(\"> {}.\".format(name))\n",
    "        s.toc(restart=True)\n",
    "        \n",
    "    return metrics_df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f897d7a",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11da76ba",
   "metadata": {},
   "source": [
    "## Sample preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16311ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_table = \"sima_station_CE\"\n",
    "target = \"pm25\"\n",
    "\n",
    "# Define columns of interest from sql table\n",
    "#     Select all columns:\n",
    "column = \"*\"\n",
    "#     Select specific columns:\n",
    "#column = \"datetime, prs, rainf, rh, sr, tout, wdr, wsr, \" + str(target)\n",
    "\n",
    "# Filter data with WHERE command\n",
    "sql_where = \"where datetime >= \\'2021-03-01\\'\"\n",
    "\n",
    "# Initialize class to create multivariate samples:\n",
    "multi_ts = multivariate_samples(sql_table, target, column, sql_where)\n",
    "\n",
    "# Datasets can't be trained with sample batches by default. So parameter is 1.\n",
    "X, y = multi_ts.samples_creation(1, target)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X[:,0,:], y, test_size = 0.30, shuffle= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1a635f",
   "metadata": {},
   "source": [
    "# Models\n",
    "We can define a list of machine learning models to evaluate on this problem. We will evaluate the models using default configurations. We are not looking for optimal configurations of these models at this point, just a general idea of how well sophisticated models with default configurations perform on this problem. We will evaluate a diverse set of nonlinear and ensemble machine learning algorithms:\n",
    "\n",
    "**Nonlinear Algorithms**:\n",
    "* k-Nearest Neighbors\n",
    "* Classification and Regression Tree\n",
    "* Support Vector Machine\n",
    "* Naive Bayes\n",
    "\n",
    "**Ensemble Algorithms**:\n",
    "* Bagged Decision Trees\n",
    "* Random Forest\n",
    "* Extra Trees\n",
    "* Gradient Boosting Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4339709",
   "metadata": {},
   "source": [
    "## Model tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "207cc528",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import SCORERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86800a74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['accuracy',\n",
       " 'adjusted_mutual_info_score',\n",
       " 'adjusted_rand_score',\n",
       " 'average_precision',\n",
       " 'balanced_accuracy',\n",
       " 'completeness_score',\n",
       " 'explained_variance',\n",
       " 'f1',\n",
       " 'f1_macro',\n",
       " 'f1_micro',\n",
       " 'f1_samples',\n",
       " 'f1_weighted',\n",
       " 'fowlkes_mallows_score',\n",
       " 'homogeneity_score',\n",
       " 'jaccard',\n",
       " 'jaccard_macro',\n",
       " 'jaccard_micro',\n",
       " 'jaccard_samples',\n",
       " 'jaccard_weighted',\n",
       " 'max_error',\n",
       " 'mutual_info_score',\n",
       " 'neg_brier_score',\n",
       " 'neg_log_loss',\n",
       " 'neg_mean_absolute_error',\n",
       " 'neg_mean_absolute_percentage_error',\n",
       " 'neg_mean_gamma_deviance',\n",
       " 'neg_mean_poisson_deviance',\n",
       " 'neg_mean_squared_error',\n",
       " 'neg_mean_squared_log_error',\n",
       " 'neg_median_absolute_error',\n",
       " 'neg_root_mean_squared_error',\n",
       " 'normalized_mutual_info_score',\n",
       " 'precision',\n",
       " 'precision_macro',\n",
       " 'precision_micro',\n",
       " 'precision_samples',\n",
       " 'precision_weighted',\n",
       " 'r2',\n",
       " 'rand_score',\n",
       " 'recall',\n",
       " 'recall_macro',\n",
       " 'recall_micro',\n",
       " 'recall_samples',\n",
       " 'recall_weighted',\n",
       " 'roc_auc',\n",
       " 'roc_auc_ovo',\n",
       " 'roc_auc_ovo_weighted',\n",
       " 'roc_auc_ovr',\n",
       " 'roc_auc_ovr_weighted',\n",
       " 'top_k_accuracy',\n",
       " 'v_measure_score']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(SCORERS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c2f15f5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 8 models:\n",
      "\n",
      "> k-Nearest Neighbors.\n",
      "Elapsed time is 0.474310 seconds.\n",
      "> Classification and Regression Tree.\n",
      "Elapsed time is 0.027777 seconds.\n",
      "> Support Vector Regression - Polynomial.\n",
      "Elapsed time is 2.098741 seconds.\n",
      "> Support Vector Regression - RBF.\n",
      "Elapsed time is 3.401193 seconds.\n",
      "> Support Vector Regression - Linear.\n",
      "Elapsed time is 1.851090 seconds.\n",
      "> Random Forest.\n",
      "Elapsed time is 10.514489 seconds.\n",
      "> Extra-trees classifier.\n",
      "Elapsed time is 0.928498 seconds.\n",
      "> XG Boost.\n",
      "Elapsed time is 21.559286 seconds.\n",
      "Elapsed time is 0.000613 seconds.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Model Name</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>R^2</th>\n",
       "      <th>Max Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ML</td>\n",
       "      <td>k-Nearest Neighbors</td>\n",
       "      <td>14.275914</td>\n",
       "      <td>10.009431</td>\n",
       "      <td>3.039451e+15</td>\n",
       "      <td>0.320154</td>\n",
       "      <td>92.535972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ML</td>\n",
       "      <td>Classification and Regression Tree</td>\n",
       "      <td>13.670001</td>\n",
       "      <td>9.815185</td>\n",
       "      <td>3.425106e+15</td>\n",
       "      <td>0.376638</td>\n",
       "      <td>73.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ML</td>\n",
       "      <td>Support Vector Regression - Polynomial</td>\n",
       "      <td>12.367335</td>\n",
       "      <td>8.432600</td>\n",
       "      <td>2.669503e+15</td>\n",
       "      <td>0.489783</td>\n",
       "      <td>87.073756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ML</td>\n",
       "      <td>Support Vector Regression - RBF</td>\n",
       "      <td>11.987484</td>\n",
       "      <td>8.147755</td>\n",
       "      <td>2.544570e+15</td>\n",
       "      <td>0.520643</td>\n",
       "      <td>68.998162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ML</td>\n",
       "      <td>Support Vector Regression - Linear</td>\n",
       "      <td>13.845888</td>\n",
       "      <td>9.637640</td>\n",
       "      <td>3.188088e+15</td>\n",
       "      <td>0.360494</td>\n",
       "      <td>127.526817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ML</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>11.984117</td>\n",
       "      <td>8.347523</td>\n",
       "      <td>3.216397e+15</td>\n",
       "      <td>0.520912</td>\n",
       "      <td>70.443078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ML</td>\n",
       "      <td>Extra-trees classifier</td>\n",
       "      <td>11.811486</td>\n",
       "      <td>8.124539</td>\n",
       "      <td>3.196433e+15</td>\n",
       "      <td>0.534615</td>\n",
       "      <td>77.809500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ML</td>\n",
       "      <td>XG Boost</td>\n",
       "      <td>12.020588</td>\n",
       "      <td>7.978760</td>\n",
       "      <td>2.990141e+15</td>\n",
       "      <td>0.517992</td>\n",
       "      <td>75.989864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Type                              Model Name       RMSE        MAE  \\\n",
       "0   ML                     k-Nearest Neighbors  14.275914  10.009431   \n",
       "1   ML      Classification and Regression Tree  13.670001   9.815185   \n",
       "2   ML  Support Vector Regression - Polynomial  12.367335   8.432600   \n",
       "3   ML         Support Vector Regression - RBF  11.987484   8.147755   \n",
       "4   ML      Support Vector Regression - Linear  13.845888   9.637640   \n",
       "5   ML                           Random Forest  11.984117   8.347523   \n",
       "6   ML                  Extra-trees classifier  11.811486   8.124539   \n",
       "7   ML                                XG Boost  12.020588   7.978760   \n",
       "\n",
       "           MAPE       R^2   Max Error  \n",
       "0  3.039451e+15  0.320154   92.535972  \n",
       "1  3.425106e+15  0.376638   73.916667  \n",
       "2  2.669503e+15  0.489783   87.073756  \n",
       "3  2.544570e+15  0.520643   68.998162  \n",
       "4  3.188088e+15  0.360494  127.526817  \n",
       "5  3.216397e+15  0.520912   70.443078  \n",
       "6  3.196433e+15  0.534615   77.809500  \n",
       "7  2.990141e+15  0.517992   75.989864  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get model list\n",
    "models = define_models()\n",
    "\n",
    "# evaluate models\n",
    "t.tic() #Start timer\n",
    "results = multiple_model_evaluation(X_train, y_train, X_test, y_test, models)\n",
    "t.toc() #Time elapsed since t.tic()\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c483e11",
   "metadata": {},
   "source": [
    "# Load and test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9effdcba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([23.7898682 , 24.46937119, 25.66182219, ..., 24.01327033,\n",
       "       16.53652162, 18.01476121])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the model of interest from disk\n",
    "filename = \"trained_ml_models/Support Vector Regression - Polynomial.sav\"\n",
    "\n",
    "loaded_model = joblib.load(filename)\n",
    "\n",
    "loaded_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c8c70c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>R^2</th>\n",
       "      <th>Max Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Support Vector Regression - Polynomial.sav</td>\n",
       "      <td>12.367335</td>\n",
       "      <td>8.4326</td>\n",
       "      <td>2.669503e+15</td>\n",
       "      <td>0.489783</td>\n",
       "      <td>87.073756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Model       RMSE     MAE  \\\n",
       "0  Support Vector Regression - Polynomial.sav  12.367335  8.4326   \n",
       "\n",
       "           MAPE       R^2  Max Error  \n",
       "0  2.669503e+15  0.489783  87.073756  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_df = pd.DataFrame(single_model_evaluation(X_train, y_train, X_test, y_test, filename[18:], loaded_model), index=[0])\n",
    "tmp_df.insert(0, \"Model\", filename[18:], True)\n",
    "tmp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb855b66",
   "metadata": {},
   "source": [
    "# Sources:\n",
    "* https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "* https://machinelearningmastery.com/save-load-machine-learning-models-python-scikit-learn/\n",
    "    \n",
    "* https://scikit-learn.org/stable/modules/svm.html\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.GaussianProcessRegressor.html    \n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
