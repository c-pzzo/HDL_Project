{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4230ec72",
   "metadata": {},
   "source": [
    "# About\n",
    "Processing environmental data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31442eae",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5e44351",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0dbb7d",
   "metadata": {},
   "source": [
    "# User-Defined Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0223dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "class raw_data_to_time_series(object):\n",
    "    \"\"\"\n",
    "    Sequential processing of data to obtain time series.\n",
    "    \n",
    "    Activities:\n",
    "    - Drop column `created` \n",
    "    - Format column `date`\n",
    "    - Split wind into two columns\n",
    "    - Split gas into multiple columns (one for each gas)\n",
    "    - Format columns\n",
    "    - Deal with duplicates\n",
    "    - Rearrange sequentially every datapoint. Highlighting missing values.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, df):\n",
    "        \"\"\"\n",
    "        df: Raw dataset\n",
    "        \"\"\"\n",
    "        self.df = df\n",
    "        self.min_date = datetime.strptime(min(self.df[\"date\"])[:10], '%Y-%m-%d')\n",
    "        self.max_date = datetime.strptime(max(self.df[\"date\"])[:10], '%Y-%m-%d')\n",
    "        self.diff_days = (self.max_date - self.min_date).days\n",
    "\n",
    "    # Processing `created` column\n",
    "    def process_created_col(self):\n",
    "        return self.df.drop(\"created\", axis = 1)\n",
    "\n",
    "    # Processing `date` column\n",
    "    def process_date_col(self):\n",
    "        df = self.process_created_col()\n",
    "        # Split rows into two columns by string \"T\"\n",
    "        tmp_date = df[\"date\"].str.split(\"T\", n = 2, expand = True)\n",
    "        \n",
    "        # Split rows of second column into two columns by string \"Z\"\n",
    "        tmp_time = tmp_date[1].str.split(\"Z\", n = 0, expand = True)\n",
    "        \n",
    "        df[\"date\"] = pd.to_datetime(df[\"date\"], format='%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "        df[\"day\"] = tmp_date[0]\n",
    "        df[\"time\"] = tmp_time[0]\n",
    "        \n",
    "        return df\n",
    "\n",
    "    # Processing `wind` column\n",
    "    def process_wind_col(self):\n",
    "        df = self.process_date_col()\n",
    "        # Split arrays in dataframe column \"wind\" into two columns\n",
    "        tmp_wind = pd.DataFrame(df[\"wind\"].to_list(), columns=['c0','c1'])\n",
    "        df[\"wind_northward\"] = tmp_wind[\"c0\"]\n",
    "        df['wind_eastward'] = tmp_wind[\"c1\"]\n",
    "        return df\n",
    "        \n",
    "    # Processing `gas` column\n",
    "    def process_gas_col(self):\n",
    "        df = self.process_wind_col()\n",
    "        \n",
    "        gas_cols = list(df[\"gas\"])\n",
    "        # Split dictionary values in column \"gas\" into three columns\n",
    "        tmp_gas = pd.DataFrame(gas_cols, columns=[\"o3\", \"no2\", \"pm25_gcc\"])\n",
    "        df[\"O3\"] = tmp_gas[\"o3\"]\n",
    "        df[\"NO2\"] = tmp_gas[\"no2\"]\n",
    "        df[\"PM25\"] = tmp_gas[\"pm25_gcc\"]\n",
    "        return df[['file_name', 'date', 'day', 'time', 'station', 'pressure', 'temp', 'precip', 'wind_northward', 'wind_eastward', 'O3', 'NO2', 'PM25']]\n",
    "    \n",
    "    # Formatting data columns\n",
    "    def data_formatting(self):\n",
    "        df = self.process_gas_col()\n",
    "        \n",
    "        df['day'] = pd.to_datetime(df['day'], format='%Y-%m-%d')\n",
    "        df['time'] = pd.to_datetime(df['time'], format='%H:%M:%S.%f').dt.time\n",
    "        df['station'] = df[\"station\"].astype(str)\n",
    "        df['pressure'] = pd.to_numeric(df[\"pressure\"], downcast='float')\n",
    "        df['temp'] = pd.to_numeric(df[\"temp\"], downcast='float')\n",
    "        df['precip'] = pd.to_numeric(df[\"precip\"], downcast='float')\n",
    "        df['wind_northward'] = pd.to_numeric(df[\"wind_northward\"], downcast='float')\n",
    "        df['wind_eastward'] = pd.to_numeric(df[\"wind_eastward\"], downcast='float')\n",
    "        df['O3'] = pd.to_numeric(df[\"O3\"], downcast='float')\n",
    "        df['NO2'] = pd.to_numeric(df[\"NO2\"], downcast='float')\n",
    "        df['PM25'] = pd.to_numeric(df[\"PM25\"], downcast='float')\n",
    "        \n",
    "        df = df.reset_index(drop = True)\n",
    "        \n",
    "        return df\n",
    "\n",
    "    # Process for similar duplicate rows\n",
    "    def duplicate_rows_test(self):    \n",
    "        processed_df = self.data_formatting()\n",
    "        processed_df= processed_df.drop_duplicates()\n",
    "        \n",
    "        sql0 = \"Select day, time, count(*) as conteo from processed_df group by day, time order by conteo desc\"\n",
    "        sql1 = \"Select * from ({}) s1 where conteo>1\".format(sql0)\n",
    "\n",
    "        if sqldf(sql1).shape[0] > 0:\n",
    "            rows_to_clean = sqldf(sql1)\n",
    "\n",
    "            # Empty dataframe to save single rows\n",
    "            single_rows = pd.DataFrame(columns = list(processed_df.columns))\n",
    "\n",
    "            # Backup the row to keep\n",
    "            for d, t in zip(rows_to_clean[\"day\"], rows_to_clean[\"time\"]):\n",
    "                # Subset of duplicate rows\n",
    "                tmp_rows = processed_df[(processed_df[\"day\"]==d) & (processed_df[\"time\"]==datetime.strptime(str(t)[:8], '%H:%M:%S').time())]\n",
    "\n",
    "                # Saving a single row from duplicates\n",
    "                single_rows = single_rows.append(tmp_rows.sort_values(\"file_name\", ascending = True)[:1])\n",
    "\n",
    "                # Delete duplicate rows from original dataframe\n",
    "                processed_df = processed_df.drop(index = list(tmp_rows.index))\n",
    "\n",
    "            processed_df = processed_df.append(single_rows)\n",
    "\n",
    "        processed_df = processed_df.sort_values([\"file_name\", \"day\", \"time\"], ascending = True)\n",
    "\n",
    "        return processed_df.reset_index(drop = True)\n",
    "\n",
    "    def time_series_df(self):\n",
    "        df = self.duplicate_rows_test()\n",
    "        \n",
    "        date_list = pd.date_range(self.min_date, freq=\"60min\", periods=(self.diff_days+1)*24).tolist()\n",
    "        date_df = pd.DataFrame(date_list, columns = [\"full_date\"])\n",
    "        \n",
    "        # This function transforms datetime into object types which facilitate column creation\n",
    "        sqlq = \"\"\"Select r1.file_name, l1.full_date as datetime, r1.day as date, r1.time, r1.station, r1.pressure, r1.temp, r1.precip, r1.wind_northward, r1.wind_eastward, r1.O3, r1.NO2, r1.PM25\n",
    "        from date_df l1 \n",
    "        left join df r1 \n",
    "        ON l1.full_date  = r1.date \n",
    "        \"\"\"\n",
    "        \n",
    "        arranged_df = sqldf(sqlq)\n",
    "        \n",
    "        tmp_time = arranged_df[\"datetime\"].str.split(\" \", n = 2, expand = True)\n",
    "        arranged_df[\"t_day\"] = tmp_time[0]\n",
    "        \n",
    "        # Trimming empty rows near min_date\n",
    "        tmp_rows = list(arranged_df[(arranged_df[\"t_day\"] == str(self.min_date.date())) & (arranged_df[\"date\"].isna())].index)\n",
    "        arranged_df = arranged_df.drop(index = tmp_rows)\n",
    "        \n",
    "        # Trimming empty rows near max_date\n",
    "        tmp_rows = list(arranged_df[(arranged_df[\"t_day\"] == str(self.max_date.date())) & (arranged_df[\"date\"].isna())].index)\n",
    "        arranged_df = arranged_df.drop(index = tmp_rows)\n",
    "        \n",
    "        arranged_df = arranged_df.drop([\"t_day\"], axis = 1)\n",
    "        arranged_df = arranged_df.drop([\"file_name\"], axis = 1)\n",
    "        \n",
    "        # The query edited the datetime format, so it is formatted again.\n",
    "        #arranged_df[\"datetime\"] = pd.to_datetime(arranged_df[\"datetime\"], format='%Y-%m-%d %H:%M:%S.%f')\n",
    "        arranged_df['date'] = pd.to_datetime(arranged_df['date'], format='%Y-%m-%d')\n",
    "        arranged_df['time'] = pd.to_datetime(arranged_df['time'], format='%H:%M:%S.%f')#.dt.time\n",
    "        \n",
    "        return arranged_df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3eeb7201",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_without_None(arr):\n",
    "    from numpy import average\n",
    "    return average([x for x in arr if x != None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d723d256",
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_data_dummy_means(df):\n",
    "    \"\"\"\n",
    "    A dummy process is defined to fill in empty values.\n",
    "    The mean is calculated from values of the previous and following week at the same hour.\n",
    "    \n",
    "    In case there are no values before or after, \n",
    "    a special UDF `mean_without_None` has been defined to deal with None values.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Filling in: `station`\n",
    "    station_num = df[df[\"station\"] != None][\"station\"][0]\n",
    "    df[\"station\"] = station_num\n",
    "\n",
    "    # Filling in: `date`, `time`\n",
    "    tmp_date = df[\"datetime\"].str.split(\" \", n = 2, expand = True)\n",
    "    df[\"date\"] = pd.to_datetime(tmp_date[0], format='%Y-%m-%d')\n",
    "    df[\"time\"] = tmp_date[1]\n",
    "\n",
    "    # After splitting datetime string, it is formatted back to datetime type to use timedelta.\n",
    "    df[\"datetime\"] = pd.to_datetime(df[\"datetime\"], format='%Y-%m-%d %H:%M:%S.%f')\n",
    "\n",
    "    # Creating copies of df\n",
    "    df_wb = df.copy()\n",
    "    df_wb[\"datetime\"] = [i + timedelta(days=7) for i in df[\"datetime\"]]\n",
    "\n",
    "    df_wa = df.copy()\n",
    "    df_wa[\"datetime\"] = [i - timedelta(days=7) for i in df[\"datetime\"]]\n",
    "\n",
    "    # Dataframe with dates to iterate through\n",
    "    dates_to_fillup = list(df[df[\"PM25\"].isnull()][\"datetime\"])\n",
    "\n",
    "    # Columns to iterate through \n",
    "    cols_to_fillup = ['pressure', 'temp', 'precip', 'wind_northward', 'wind_eastward', 'O3', 'NO2', 'PM25']\n",
    "\n",
    "    # Update\n",
    "    for i in dates_to_fillup:\n",
    "        for j in cols_to_fillup:\n",
    "            df.at[list(df[df[\"datetime\"] == i].index),j]=mean_without_None([df_wb[df_wb[\"datetime\"] == i][j].values[0], df_wa[df_wa[\"datetime\"] == i][j].values[0]])\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cda8f389",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_ts_data_preparation(folder_raw_data, station_number):\n",
    "    # ------------------\n",
    "    # Importing Data\n",
    "    # ------------------\n",
    "    print(\"Data preparation process for {}\".format(station_number))\n",
    "    \n",
    "    # Concatenating raw data from multiple JSON files\n",
    "    files_list = list(glob.iglob('{}{}*.json'.format(folder_raw_data, station_number)))\n",
    "\n",
    "    # Defining empty list of dictionaries\n",
    "    raw_data = list(dict())\n",
    "\n",
    "    # Extending list of daily dictionaries\n",
    "    for i in files_list:\n",
    "        tmp = json.load(open(i))\n",
    "        # Adding column \"file_name\"\n",
    "        tmp = list(map(lambda item: dict(item, file_name=i[len(folder_raw_data):]), tmp))\n",
    "        raw_data.extend(tmp)\n",
    "\n",
    "    col_names = list(raw_data[0].keys())\n",
    "\n",
    "    raw_df = pd.DataFrame(raw_data, columns=col_names)\n",
    "\n",
    "    # ------------------\n",
    "    # Data Processing\n",
    "    # ------------------\n",
    "\n",
    "    # Initialization of processing class\n",
    "    main_processed_df = raw_data_to_time_series(raw_df)\n",
    "\n",
    "    # Execution of processing functions\n",
    "    processed_df = main_processed_df.time_series_df()\n",
    "\n",
    "    # ------------------\n",
    "    # Missing data \n",
    "    # ------------------\n",
    "    update_df = missing_data_dummy_means(processed_df)\n",
    "    \n",
    "    return update_df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b54d4da",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b731dc4",
   "metadata": {},
   "source": [
    "The data returned will have the following units:\n",
    "\n",
    "|Columns|Description|\n",
    "|---\t|---\t|\n",
    "|created|Data point creation date|\n",
    "|date   |Measurement time|\n",
    "|station|Meteorological station number|\n",
    "|pressure|Surface Pressure (hPa)|\n",
    "|temp|Temperature (K)|\n",
    "|precipitation|Precipitation (mm)|\n",
    "|wind|Wind (ms^-1)|\n",
    "|gas|Including O3, NO2, PM2.5 (ug/m3)|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b805788e",
   "metadata": {},
   "source": [
    "# Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "89f7d285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preparation process for s71\n"
     ]
    }
   ],
   "source": [
    "folder_raw_data = 'RawData/'\n",
    "station_number = 's71'\n",
    "\n",
    "df = full_ts_data_preparation(folder_raw_data, station_number)\n",
    "df.to_csv('TimeSeriesFiles/{}_ts.csv'.format(station_number), encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b8d937b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pressure</th>\n",
       "      <th>temp</th>\n",
       "      <th>precip</th>\n",
       "      <th>wind_northward</th>\n",
       "      <th>wind_eastward</th>\n",
       "      <th>O3</th>\n",
       "      <th>NO2</th>\n",
       "      <th>PM25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8784.000000</td>\n",
       "      <td>8784.000000</td>\n",
       "      <td>8784.000000</td>\n",
       "      <td>8784.000000</td>\n",
       "      <td>8784.000000</td>\n",
       "      <td>8784.000000</td>\n",
       "      <td>8784.000000</td>\n",
       "      <td>8784.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>893.285809</td>\n",
       "      <td>293.671323</td>\n",
       "      <td>41.921143</td>\n",
       "      <td>-1.243791</td>\n",
       "      <td>-0.197175</td>\n",
       "      <td>41.282197</td>\n",
       "      <td>15.109253</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.065992</td>\n",
       "      <td>6.689914</td>\n",
       "      <td>318.338548</td>\n",
       "      <td>1.585070</td>\n",
       "      <td>0.978695</td>\n",
       "      <td>22.505106</td>\n",
       "      <td>4.448817</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>879.658386</td>\n",
       "      <td>270.919312</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.936700</td>\n",
       "      <td>-4.024300</td>\n",
       "      <td>-0.316800</td>\n",
       "      <td>-0.130100</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>890.664337</td>\n",
       "      <td>289.613647</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.257325</td>\n",
       "      <td>-0.864475</td>\n",
       "      <td>23.285376</td>\n",
       "      <td>12.300625</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>893.267792</td>\n",
       "      <td>294.030991</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.298950</td>\n",
       "      <td>0.043000</td>\n",
       "      <td>36.388149</td>\n",
       "      <td>15.396450</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>895.803528</td>\n",
       "      <td>298.560028</td>\n",
       "      <td>3.285700</td>\n",
       "      <td>-0.288625</td>\n",
       "      <td>0.551000</td>\n",
       "      <td>57.519650</td>\n",
       "      <td>17.876976</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>908.806091</td>\n",
       "      <td>309.545593</td>\n",
       "      <td>8224.487305</td>\n",
       "      <td>7.262100</td>\n",
       "      <td>1.957500</td>\n",
       "      <td>121.299202</td>\n",
       "      <td>33.250801</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          pressure         temp       precip  wind_northward  wind_eastward  \\\n",
       "count  8784.000000  8784.000000  8784.000000     8784.000000    8784.000000   \n",
       "mean    893.285809   293.671323    41.921143       -1.243791      -0.197175   \n",
       "std       4.065992     6.689914   318.338548        1.585070       0.978695   \n",
       "min     879.658386   270.919312     0.000000       -5.936700      -4.024300   \n",
       "25%     890.664337   289.613647     0.000000       -2.257325      -0.864475   \n",
       "50%     893.267792   294.030991     0.000000       -1.298950       0.043000   \n",
       "75%     895.803528   298.560028     3.285700       -0.288625       0.551000   \n",
       "max     908.806091   309.545593  8224.487305        7.262100       1.957500   \n",
       "\n",
       "                O3          NO2    PM25  \n",
       "count  8784.000000  8784.000000  8784.0  \n",
       "mean     41.282197    15.109253     0.0  \n",
       "std      22.505106     4.448817     0.0  \n",
       "min      -0.316800    -0.130100     0.0  \n",
       "25%      23.285376    12.300625     0.0  \n",
       "50%      36.388149    15.396450     0.0  \n",
       "75%      57.519650    17.876976     0.0  \n",
       "max     121.299202    33.250801     0.0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "557aa47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8880 entries, 0 to 8879\n",
      "Data columns (total 12 columns):\n",
      " #   Column          Non-Null Count  Dtype         \n",
      "---  ------          --------------  -----         \n",
      " 0   datetime        8880 non-null   datetime64[ns]\n",
      " 1   date            8880 non-null   datetime64[ns]\n",
      " 2   time            8880 non-null   object        \n",
      " 3   station         8880 non-null   object        \n",
      " 4   pressure        8784 non-null   float64       \n",
      " 5   temp            8784 non-null   float64       \n",
      " 6   precip          8784 non-null   float64       \n",
      " 7   wind_northward  8784 non-null   float64       \n",
      " 8   wind_eastward   8784 non-null   float64       \n",
      " 9   O3              8784 non-null   float64       \n",
      " 10  NO2             8784 non-null   float64       \n",
      " 11  PM25            8784 non-null   float64       \n",
      "dtypes: datetime64[ns](2), float64(8), object(2)\n",
      "memory usage: 832.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea939deb",
   "metadata": {},
   "source": [
    "# Relevant sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3dad95",
   "metadata": {},
   "source": [
    "Monterrey Raw Data:\n",
    "* Obispado: http://gmao-aq-prod-1707436367.us-east-1.elb.amazonaws.com/station/32\n",
    "* San Pedro: http://gmao-aq-prod-1707436367.us-east-1.elb.amazonaws.com/station/71\n",
    "* La Pastora: http://gmao-aq-prod-1707436367.us-east-1.elb.amazonaws.com/station/31\n",
    "\n",
    "Raw data information:\n",
    "* https://resourcewatch.org/data/explore/cit004rw0-City-AQ-Forecasts?hash=further_information&section=Discover&selectedCollection=&zoom=0.8217739819705677&lat=0&lng=120.5424929385674&pitch=0&bearing=0&basemap=dark&labels=light&layers=%255B%257B%2522dataset%2522%253A%2522f5599d62-7f3d-41c7-b3fd-9f8e08ee7b2a%2522%252C%2522opacity%2522%253A1%252C%2522layer%2522%253A%252249ecb5d5-c9b0-4d4e-b049-aa872dd1a084%2522%257D%255D&aoi=&page=1&sort=most-viewed&sortDirection=-1\n",
    "* https://airquality.gsfc.nasa.gov/cityaq-pilot-combine-local-monitoring-data-geos-cf-model-outputs-develop-city-scale-operational\n",
    "\n",
    "Python Documentation:\n",
    "* https://www.geeksforgeeks.org/read-json-file-using-python/\n",
    "* https://docs.python.org/3/library/datetime.html#strftime-and-strptime-behavior\n",
    "\n",
    "Papers:\n",
    "* https://www.intechopen.com/chapters/74059\n",
    "* https://www.sciencedirect.com/science/article/pii/S0167739X21003794\n",
    "* https://www.researchgate.net/publication/335752400_Filling_the_gaps_of_in-situ_hourly_PM25_concentration_data_with_the_aid_of_empirical_orthogonal_function_constrained_by_diurnal_cycles\n",
    "\n",
    "\n",
    "Others (Books, forums)\n",
    "* https://www.researchgate.net/post/How-can-I-fill-the-missing-climatological-data\n",
    "* https://www.fao.org/3/x0490e/x0490e07.htm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
